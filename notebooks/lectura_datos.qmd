---
title: "Lectura de datos"
format: html
date: last-modified
author:
  - name: Víctor Gauto
    orcid: 0000-0001-9960-8558
    corresponding: true
    email: victor.gauto@ca.frre.utn.edu.ar
    affiliations:
      - name: GISTAQ (UTN-FRRe)
        url: https://www.instagram.com/gistaq.utn/
      - name: IIDTHH (UNNE, CONICET)
        url: https://iidthh.conicet.gov.ar/
      - name: Instituto Gulich (UNC, CONAE)
        url: https://ig.conae.unc.edu.ar/
execute:
  eval: false
  echo: true
code-annotations: hover
editor_options:
  chunk_output_type: console
---

Los datos se dividen en dos grupos, datos numéricos y ráster, de acuerdo al formato en el que se presentan. Esto determina los paquetes requeridos y las operaciones necesarias para trabajar con estos.

# Datos numéricos

Estos datos son aquellos que se registran en un archivo Excel, que incluyen los datos recolectados in situ al momento de tomar la muestra de agua sobre el río Paraná; y los resultados de los ensayos de laboratorio.

- In situ: latitud y longitud geográfica, profundidad de disco de Secchi, conductividad y pH.

- Ensayos de laboratorio: sólidos suspendidos y turbidez.

```{r}
datos <- readxl::read_xlsx(
  path = x,
  sheet = 1,
  .name_repair = "unique_quiet"
) |>
  select( # <1>
    fecha = 1, longitud = 4, latitud = 5, # <1>
    ph = 6, cond = 8, secchi = 10, # <1>
    sol_sus = 12, turb = 13, hazemeter = 14 # <1>
  ) |> # <1>
  fill(fecha) |>
  mutate(fecha = ymd(fecha)) |>
  pivot_longer( # <2>
    cols = -c(fecha, latitud, longitud), # <2>
    names_to = "param", # <2>
    values_to = "valor" # <2>
  ) |> # <2>
  drop_na(valor, latitud, longitud)

write_csv(datos, "datos/base_de_datos_lab.csv") # <3>
```
1. Selecciono las columnas de interés y cambio de nombre.
2. Transformo a tabla larga para una mejor organización de los datos.
3. Almaceno los resultados en una base de datos.

Los datos presentan la siguiente estructura.

```{r}
#| echo: false
#| eval: true
#| warning: false

readr::read_csv(
  file = "../datos/base_de_datos_lab.csv",
  show_col_types = FALSE
) |>
  head()
```

# Ráster

Las imágenes satelitales se obtienen a partir del catálogo [Copernicus Data Space](https://dataspace.copernicus.eu/). La solicitud require un rango de fecha alrededor de la adquisición de la escena, las coordenadas de la imagen, la colección de interés y el nivel de procesamiento.

Es requisito poseer una [cuenta de usuario](https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/auth?client_id=cdse-public&response_type=code&scope=openid&redirect_uri=https%3A//dataspace.copernicus.eu/account/confirmed/1) para acceder a la descarga del producto.

```{python}
import requests  # <1>
import pandas as pd  # <1>
from datetime import datetime, timedelta  # <1>
import os  # <1>
import certifi  # <1>
import json  # <1>

catalogue_odata_url = "https://catalogue.dataspace.copernicus.eu/odata/v1"

collection_name = "SENTINEL-2"  # <2>
product_type = "S2MSI2A"  # <2>
max_cloud_cover = 1  # <2>
aoi = "POINT(-58.81348666883592 -27.488354054598737)"  # <2>
search_period_start = "2024-01-01T00:00:00.000Z"  # <2>
search_period_end = "2024-01-02T00:00:00.000Z"  # <2>
```
1. Cargo todas las librerías.
2. Indico colección, nivel de procesamiento, ubicación del <i>tile</i> y rango de fechas.

Con los datos mostrados se crea un <i>query</i> y con las credenciales de usuario se accede mediante el token generado.

```{python}
search_query = f"{catalogue_odata_url}/Products?$filter=Collection/Name eq '{collection_name}' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq '{product_type}') and OData.CSC.Intersects(area=geography'SRID=4326;{aoi}') and ContentDate/Start gt {search_period_start} and ContentDate/Start lt {search_period_end}"

response = requests.get(search_query).json()
result = pd.DataFrame.from_dict(response["value"])  # <1>

username = os.environ["COPERNICUS_USERNAME"]  # <2>
password = os.environ["COPERNICUS_PASSWORD"]  # <2>

auth_server_url = "https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token"
data = {
    "client_id": "cdse-public",
    "grant_type": "password",
    "username": username,
    "password": password,
}

response_cred = requests.post(
    auth_server_url, data=data, verify=True, allow_redirects=False
)
access_token = json.loads(response_cred.text)["access_token"]
```
1. Transformo la respuesta del servidor a tabla.
2. Credenciales de usuario.

La descarga se realiza a partir de un loop en caso de existir múltiples productos disponibles.

```{python}
if len(result) == 0:  # <1>
    print(
      "\n\n--- NO HAY PRODUCTO DISPONIBLE PARA EL DÍA DE LA FECHA ---\n\n"
    )
elif os.path.isfile("producto/producto.zip") == True:
    print("\n\n--- PRODUCTO YA DESCARGADO ---\n\n")  # <2>
else:
    producto_id = result["Id"][0]
    producto_nombre = result["Name"][0]

    print("ID del producto", producto_id)
    print("Nombre del producto", producto_nombre)

    # URL de descarga del producto
    url = f"https://zipper.dataspace.copernicus.eu/odata/v1/Products({producto_id})/$value"

    headers = {"Authorization": f"Bearer {access_token}"}

    session = requests.Session()
    session.headers.update(headers)
    response_prod = session.get(url, headers=headers, stream=True)

    print("\n\n--- DESCARGANDO PRODUCTO ---\n\n")

    with open("producto/producto.zip", "wb") as file:  # <3>
        for chunk in response_prod.iter_content(chunk_size=8192):
            if chunk:
                file.write(chunk)

    print("\n\n--- PRODUCTO DESCARGADO ---\n\n")
```
1. En caso que no haya resultados de búsqueda, se detiene el loop con un mensaje.
2. Si el producto fue previamente descargado, que se detiene el loop.
3. Almaceno el producto como archivo comprimido (`.zip`).

La [documentación](https://documentation.dataspace.copernicus.eu/APIs/OData.html) de la API resultó de gran ayuda para este desarrollo.
