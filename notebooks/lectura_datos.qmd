---
title: "Lectura de datos"
type: html
date: last-modified
author:
  - name: Víctor Gauto
    orcid: 0000-0001-9960-8558
    corresponding: true
    email: victor.gauto@ca.frre.utn.edu.ar
    affiliations:
      - <a href='https://www.instagram.com/gistaq.utn/' target="_blank">GISTAQ (UTN-FRRe)</a>
      - <a href='https://iidthh.conicet.gov.ar/' target="_blank">IIDTHH (UNNE, CONICET)</a>
      - <a href='https://ig.conae.unc.edu.ar/' target="_blank">Instituto Gulich (UNC, CONAE)</a>
execute:
  eval: false
  echo: true
code-annotations: hover
editor_options:
  chunk_output_type: console
---

Los datos se dividen en dos grupos de acuerdo al formato en el que se presentan, lo cual determina los paquetes requeridos y las operaciones necesarias para trabajar con estos.

# Datos numéricos

Los datos de laboratorio se extraen del archivo Excel que es completado luego de finalizar cada ensayo.

Del mismo se obtienen las mediciones in situ junto con las coordenadas geográficas de los puntos de muestreo.

Las variables de interés son: fecha, longitud y latitud, pH, conductividad, sólidos suspendidos y turbidez.

```{r}
datos <- readxl::read_xlsx(
  path = x,
  sheet = 1,
  .name_repair = "unique_quiet") |>
  select( # <1>
    fecha = 1, longitud = 4, latitud = 5, # <1>
    ph = 6, cond = 8, secchi = 10, # <1>
    sol_sus = 12, turb = 13, hazemeter = 14) |> # <1>
  fill(fecha) |>
  mutate(fecha = ymd(fecha)) |>
  pivot_longer( # <2>
    cols = -c(fecha, latitud, longitud), # <2>
    names_to = "param", # <2>
    values_to = "valor" # <2>
  ) |> # <2>
  drop_na(valor, latitud, longitud)

write_csv(datos, "datos/base_de_datos_lab.csv") # <3>
```
1. Selecciono las columnas de interés y cambio de nombre.
2. Transformo a tabla larga para una mejor organización de los datos.
3. Almaceno los resultados en una base de datos.

```{r}
#| echo: false
#| eval: true
#| warning: false

readr::read_csv(
  file = "../datos/base_de_datos_lab.csv",
  show_col_types = FALSE
) |>
  head()
```

# Ráster

Las imágenes satelitales se obtienen a partir del catálogo de Copernicus. La solicitud require un rango de fecha en torno a la adquisición de la escena, las coordenadas de la imagen y el nivel de procesamiento.

```{python}
import requests # <1>
import pandas as pd # <1>
from datetime import datetime, timedelta # <1>
import os # <1>
import certifi # <1>
import json # <1>

catalogue_odata_url = "https://catalogue.dataspace.copernicus.eu/odata/v1"

collection_name = "SENTINEL-2" # <2>
product_type = "S2MSI2A" # <2>
max_cloud_cover = 1 # <2>
aoi = "POINT(-58.81348666883592 -27.488354054598737)" # <2>
search_period_start = "2024-01-01T00:00:00.000Z" # <2>
search_period_end = "2024-01-02T00:00:00.000Z" # <2>
```
1. Cargo todas las librerías.
2. Indico producto, posición y fechas de interés.

Con los datos mostrados se genera un <i>query</i> y con las credenciales de usuario de la plataforma se accede mediante el token.

```{python}
search_query = f"{catalogue_odata_url}/Products?$filter=Collection/Name eq '{collection_name}' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq '{product_type}') and OData.CSC.Intersects(area=geography'SRID=4326;{aoi}') and ContentDate/Start gt {search_period_start} and ContentDate/Start lt {search_period_end}"

response = requests.get(search_query).json()
result = pd.DataFrame.from_dict(response["value"]) # <1>

username = os.environ['COPERNICUS_USERNAME'] # <2>
password = os.environ['COPERNICUS_PASSWORD'] # <2>

auth_server_url = "https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token"
data = {
    "client_id": "cdse-public",
    "grant_type": "password",
    "username": username,
    "password": password,
}

response_cred = requests.post(
  auth_server_url, data = data, verify = True, allow_redirects = False
)
access_token = json.loads(response_cred.text)["access_token"]
```
1. Transformo la respuesta del servidor a tabla.
2. Credenciales de usuario.

La descarga se realiza a partir de un loop en caso de existir múltiples productos disponibles.

```{python}
if len(result) == 0: # <1>
    print("\n\n--- NO HAY PRODUCTO DISPONIBLE PARA EL DÍA DE LA FECHA ---\n\n")
elif os.path.isfile("producto/producto.zip") == True:
    print("\n\n--- PRODUCTO YA DESCARGADO ---\n\n") # <2>
else:
    producto_id = result["Id"][0]
    producto_nombre = result["Name"][0]

    print("ID del producto", producto_id)
    print("Nombre del producto", producto_nombre)

    # URL de descarga del producto
    url = f"https://zipper.dataspace.copernicus.eu/odata/v1/Products({producto_id})/$value"

    headers = {"Authorization": f"Bearer {access_token}"}

    session = requests.Session()
    session.headers.update(headers)
    response_prod = session.get(url, headers=headers, stream=True)

    print("\n\n--- DESCARGANDO PRODUCTO ---\n\n")

    with open("producto/producto.zip", "wb") as file:  # <3>
        for chunk in response_prod.iter_content(chunk_size=8192):
            if chunk:
                file.write(chunk)

    print("\n\n--- PRODUCTO DESCARGADO ---\n\n")
```
1. En caso que no haya resultados de búsqueda, que no continúe con el loop.
2. Si el producto fue previamente descargado, que se detenga.
3. Almaceno el producto como archivo comprimido (`.zip`).

La [documentación](https://documentation.dataspace.copernicus.eu/APIs/OData.html) de Data Space Copernicus resultó de gran ayuda para este desarrollo.
